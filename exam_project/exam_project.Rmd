---
title: "Problem B: Short-term effect of air pollution on mortality"
output: html_document
author: "Ginevra Carbone"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(SemiPar)
library(dplyr)
library(ggplot2)
library(tidyr)
library(rstanarm)
library(rstan)
library(bayesplot)
data("milan.mort")
```

The R package `SemiPar` contains the `milan.mort` dataset on short-term effect of air pollution on mortality. The data comprise 3,652 observations on 9 variables, whose description can be found in the help file. The data are also analysed in the book by Ruppert, Wand and Carroll (2003). The original reference is:

Vigotti, M.A., Rossi, G., Bisanti, L., Zanobetti, A. and Schwartz, J. (1996). Short term effect of urban air pollution on respiratory health in Milan, Italy, 1980-1989. Journal of Epidemiology and Community Health, 50, 71-75.

After performing some explorative analyses:


## Part 1
Taking `total.mort` (or a suitable transformation of it) as a normally distributed response variable, build a model for the average number of deaths, checking if some of the covariates may have a nonlinear effect (do not consider the `resp.mort` variable). Follow a Bayesian approach for the task and check the model fit via pp checks.

```{r}
# data summary
summary(milan.mort)

# tot.mort histogram
ggplot(milan.mort, aes(x = tot.mort)) + 
  geom_bar()

# tot.mort histogram by week day
ggplot(milan.mort, aes(x=tot.mort)) + 
  geom_bar(aes(fill=factor(day.of.week)), width = 0.5)

# avg number of deaths
milan.mort %>% summarize(mean(tot.mort))

# relationship bw number of deaths and S02

# color by holiday
ggplot(milan.mort, aes(x = SO2, y = tot.mort, color = factor(holiday))) + 
    geom_jitter()

# color by day of week
ggplot(milan.mort, aes(x = SO2, y = tot.mort, color = factor(day.of.week))) + 
    geom_jitter()

# pairplots for numerical variables
pairs(tot.mort ~ mean.temp + rel.humid + SO2 + TSP, data=milan.mort)

```

### model 1

We start with a very simple model

$$
\text{tot_mort}_i \sim \mathcal{N}(\mu,\sigma^2)\\
\mu = \alpha + \beta\; \text{SO2}_i
$$
non-informative uniform prior distributions on $\alpha,\beta$ and a Caychy prior on $\sigma \sim Cauchy(0,30)$.

```{r stan simple_informative}
## arrange data into a list
data <- list(
  N = nrow(milan.mort), 
  tot_mort = milan.mort$tot.mort,
  SO2 = milan.mort$SO2
  #TSP = milan.mort$TSP
  #mean.temp = milan.mort$mean.temp
  #rel.humid = milan.mort$rel.humid
)

## compile the model
simple_informative <- stan_model("simple_informative.stan")

## fit the model
simple_informative_fit <- sampling(simple_informative, data = data)

# parameters distributions
mcmc_hist(as.matrix(simple_informative_fit, pars = c('alpha','beta')))

## posterior predictive checking
y_rep <- as.matrix(simple_informative_fit, pars = "y_rep")
ppc_dens_overlay(y = milan.mort$tot.mort, y_rep[1:200,])

## standardised residuals of the observed vs predicted number of complaints
mean_y_rep <- colMeans(y_rep)
std_resid <- (milan.mort$tot.mort - mean_y_rep) / sqrt(mean_y_rep)
qplot(mean_y_rep, std_resid) + hline_at(2) + hline_at(-2)

# mean estimate comparison
ppc_stat(y = y, yrep = y_rep, stat = "mean")
mean(y)
mean(y_rep)
```

Residuals look evenly distributed between positive and negative values. This means that the model does not understimate or overestimate the outcome values.

The problem with this model is that the mean value estimate is inaccurate.


## model 2

Now we test the same model on $\mathcal{N}(0,1)$ priors for $\alpha$ and $\beta$.

```{r stan model2}

## compile the model
simple_non_informative <- stan_model("simple_non_informative.stan")

## fit the model
simple_non_informative_fit <- sampling(simple_non_informative, data = data1)

# parameters distributions
mcmc_hist(as.matrix(simple_non_informative_fit, pars = c('alpha','beta')))

## posterior predictive checking
y_rep <- as.matrix(simple_non_informative_fit, pars = "y_rep")
ppc_dens_overlay(y = milan.mort$tot.mort, y_rep[1:200,])

# mean estimate comparison
ppc_stat(y = y, yrep = y_rep, stat = "mean")
mean(y)
mean(y_rep)
```

We can notice that the estimated mean 

*!!!!finire di commentare*

## model 3

In the third model we take into account the hierarchical structure of the data among different days of the week.

*perchÃ© non considero ad esempio una rappresentazione gerarchica rispetto ai giorni di holiday?*

```{r model3}
```


## Part 2 [optional]

Model the nonlinear effects of some covariates.

```{r}

ggplot(data = milan.mort, aes(log(SO2),tot.mort,
                              colour=day.of.week))+geom_point()

ggplot(data = milan.mort, aes(TSP,tot.mort,
                              colour=day.of.week))+geom_point()

ggplot(data = milan.mort, aes(mean.temp,tot.mort,
                              colour=day.of.week))+geom_point()

ggplot(data = milan.mort, aes(rel.humid,tot.mort,
                              colour=day.of.week))+geom_point()

covariates <- milan.mort %>% 
  select(-c("tot.mort","resp.mort")) %>% 
  colnames()

for(i in range(length(covariates))){
  print(ggplot(data = milan.mort, 
        aes_string(x=covariates[i],y="tot.mort")) + geom_point())
}

```

## Part 3

Now consider a GLM with a Poisson distributed response for `total.mort`, comparing the fitted response values with those obtained previously.

```{r}


fit1 <- glm (formula=tot.mort ~ TSP + SO2 + ,
                 data=milan.mort, 
                 family=poisson(link="log"))

fit <- stan_glm (formula=tot.mort ~ TSP + log(SO2),
                 data=milan.mort, 
                 family=poisson(link="identity"))

print(fit)
```
